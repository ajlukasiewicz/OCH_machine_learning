{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Coding Hour Machine Learning Workshop\n",
    "By Matthew Smith and Alexandra Lukasiewicz\n",
    "\n",
    "Thanks for joining us on Kaggle! This website hosts a wide variety of datasets and examples of machine learning in different programming languages. We've found it very useful in creating this tutorial.\n",
    "\n",
    "### During this workshop we will demonstrate two examples of machine learning using the Scikit-Learn python package\n",
    "#### These are:\n",
    "1. Supervised learning (in our example: generating a classifier)\n",
    "1. Unsupervised learning- (clustering to observe patterns of similarity in the dataset)\n",
    "\n",
    "### We will be working with two datasets from the [UCI machine learning repository](https://archive.ics.uci.edu/ml/index.php)\n",
    "* [Mushrooms](https://www.kaggle.com/uciml/mushroom-classification) (a dataset containing key mushroom identification features and their edibility) \n",
    "* [Wine](https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009) (A dataset containing features of different red wines such as acidity and sugar content and their quality score)\n",
    "\n",
    "![](https://media.winefolly.com/Wine-pairing-portobello-mushroom-pinot-winefolly-1.jpg)\n",
    "Image from \"Wine and Grill Food Pairings Made For The Porch\" by Phil Keelig, Wine Folly\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to machine learning \n",
    "### What are examples of questions you can ask using ML tools in scikit learn?\n",
    "ML can be useful in answering biological questions where the exact steps or conditions that generate an outcome are unknown. \n",
    "An example can include: \n",
    "* Thermodynamic models with series of complex steps. \n",
    "* Metabolic engineering (Presnell and Alper 2020)\n",
    "* Identifying patterns in systems (unsupervised clustering)\n",
    "* Reducing heterogenous datasets (dimensionality reduction)\n",
    "\n",
    "### What are challenges in machine learning?\n",
    "**Poor dataset**\n",
    "* Training dataset has too few entries \n",
    "* Dataset is not representative of new cases it will encounter \n",
    "* Irrelevant features\n",
    "\n",
    "**Poor algorithm**\n",
    "* Overfitting to training dataset\n",
    "* Underfitting the training dataset (not enough factors included to be accurate when presented with new information)\n",
    "\n",
    "### Applying machine learning in your own research\n",
    "**Generating hypotheses**\n",
    "* Unsupervised clustering to observe patterns in data \n",
    "* Defining a clear goal or question to answer (am I categorizing data? Am I predicting a value (such as binding strength or enzyme production?)\n",
    "\n",
    "**Evaluating dataset (do I need more information?)** \n",
    "* Selecting a set of algorithms for your question\n",
    "* Evaluating performance \n",
    "\n",
    "### Choosing the right language for you\n",
    "* Caret library in R\n",
    "* Tensorflow (google) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To begin, we will import packages and datasets for the rest of the workshop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages for dataframe manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#scikit-learn specific packages:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import mushroom and wine datasets \n",
    "mushrooms = pd.read_csv(\"../input/mushroom-classification/mushrooms.csv\")\n",
    "\n",
    "wine = pd.read_csv(\"../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick modification of the Wine dataset\n",
    "Wine contains the column 'quality' which contains numeric scores. For the purposes of using this dataset for classification we will convert this column to 'poor' or 'excellent' given an arbitrary cutoff score of 7. \n",
    "\n",
    "'quality' will be our column of categorical variables, and 'quality_score' will hold our numeric values. If you would like to use this dataset to generate a numeric predictor of quality, you can use several algorithmic approaches including linear regression, L1 or L2 regularization, SVMs, or even Decision trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert columns in wine to categorical values \n",
    "wine = wine.rename(columns = {\"quality\":'quality_score'})\n",
    "cutoff_key = {range(0,7):'poor', range(7,10):'excellent'}\n",
    "wine['quality'] = wine['quality_score'].apply(lambda x: next((v for k, v in cutoff_key.items() if x in k), 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets take a look at our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0            c         n          k  ...                        s   \n",
       "1            c         b          k  ...                        s   \n",
       "2            c         b          n  ...                        s   \n",
       "3            c         n          n  ...                        s   \n",
       "4            w         b          k  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mushrooms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with non-numeric data\n",
    "Each of the columns contain different features of a mushroom that will help us classify whether our sample is edible or poisonous \n",
    "However, these are all in a non-numeric format and not all ML algorithms support categorical variables. \n",
    "We can use the scikit-learn tool Label Encoder to convert our dataset into a numeric format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "0      1          5            2          4        1     6                1   \n",
       "1      0          5            2          9        1     0                1   \n",
       "2      0          0            2          8        1     3                1   \n",
       "3      1          5            3          8        1     6                1   \n",
       "4      0          5            2          3        0     5                1   \n",
       "\n",
       "   gill-spacing  gill-size  gill-color  ...  stalk-surface-below-ring  \\\n",
       "0             0          1           4  ...                         2   \n",
       "1             0          0           4  ...                         2   \n",
       "2             0          0           5  ...                         2   \n",
       "3             0          1           5  ...                         2   \n",
       "4             1          0           4  ...                         2   \n",
       "\n",
       "   stalk-color-above-ring  stalk-color-below-ring  veil-type  veil-color  \\\n",
       "0                       7                       7          0           2   \n",
       "1                       7                       7          0           2   \n",
       "2                       7                       7          0           2   \n",
       "3                       7                       7          0           2   \n",
       "4                       7                       7          0           2   \n",
       "\n",
       "   ring-number  ring-type  spore-print-color  population  habitat  \n",
       "0            1          4                  2           3        5  \n",
       "1            1          4                  3           2        1  \n",
       "2            1          4                  3           2        3  \n",
       "3            1          4                  2           3        5  \n",
       "4            1          0                  3           0        1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "for col in mushrooms.columns:\n",
    "    mushrooms[col] = le.fit_transform(mushrooms[col])\n",
    "\n",
    "mushrooms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that the \"class\" column of (e)dible or (p)oisonous has been converted into a binary of 0 or 1. In addition all of the other letter categories have been converted into a number "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we use dummy variables?\n",
    "\n",
    "After converting our variables into numbers, we still have a problem. Most of our columns have more than 2 possibilities. For example, look at “cap-surface” in the mushroom data-set - it has three possibilities. If we look at these as numerical values, then we are artificially grouping things together that may have no relation. Most machine learning algorithms will have an easy time separating cap-surface 1 and 2 from cap-surface 3, or separating cap-surface 2 and 3 from caps-surface 1, but these algorithms will have a more difficult time (or even find it impossible), to separate cap-surface 1 and 3 from cap-surface 2. As the number of these classifications goes up for a column, this problem gets worse.\n",
    "\n",
    "To fix this, we can break our existing columns each into multiple dummy columns. Each column is broken into the number of columns equal to its number of classifications. Then for the cap-surface N column, the value is 1 if the cap-surface is type N, and it’s 0 otherwise. This lets your machine learning algorithm handle arbitrary relationships between the classifications in a particular column of the original data-set.\n",
    "uld you add info here about the dummy variable section?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_1</th>\n",
       "      <th>cap-shape_1</th>\n",
       "      <th>cap-shape_2</th>\n",
       "      <th>cap-shape_3</th>\n",
       "      <th>cap-shape_4</th>\n",
       "      <th>cap-shape_5</th>\n",
       "      <th>cap-surface_1</th>\n",
       "      <th>cap-surface_2</th>\n",
       "      <th>cap-surface_3</th>\n",
       "      <th>cap-color_1</th>\n",
       "      <th>...</th>\n",
       "      <th>population_2</th>\n",
       "      <th>population_3</th>\n",
       "      <th>population_4</th>\n",
       "      <th>population_5</th>\n",
       "      <th>habitat_1</th>\n",
       "      <th>habitat_2</th>\n",
       "      <th>habitat_3</th>\n",
       "      <th>habitat_4</th>\n",
       "      <th>habitat_5</th>\n",
       "      <th>habitat_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_1  cap-shape_1  cap-shape_2  cap-shape_3  cap-shape_4  cap-shape_5  \\\n",
       "0        1            0            0            0            0            1   \n",
       "1        0            0            0            0            0            1   \n",
       "2        0            0            0            0            0            0   \n",
       "3        1            0            0            0            0            1   \n",
       "4        0            0            0            0            0            1   \n",
       "\n",
       "   cap-surface_1  cap-surface_2  cap-surface_3  cap-color_1  ...  \\\n",
       "0              0              1              0            0  ...   \n",
       "1              0              1              0            0  ...   \n",
       "2              0              1              0            0  ...   \n",
       "3              0              0              1            0  ...   \n",
       "4              0              1              0            0  ...   \n",
       "\n",
       "   population_2  population_3  population_4  population_5  habitat_1  \\\n",
       "0             0             1             0             0          0   \n",
       "1             1             0             0             0          1   \n",
       "2             1             0             0             0          0   \n",
       "3             0             1             0             0          0   \n",
       "4             0             0             0             0          1   \n",
       "\n",
       "   habitat_2  habitat_3  habitat_4  habitat_5  habitat_6  \n",
       "0          0          0          0          1          0  \n",
       "1          0          0          0          0          0  \n",
       "2          0          1          0          0          0  \n",
       "3          0          0          0          1          0  \n",
       "4          0          0          0          0          0  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mushrooms = pd.get_dummies(mushrooms,columns=mushrooms.columns,drop_first=True)\n",
    "mushrooms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset into training and testing sets \n",
    "Splitting your dataset into training and testing sets is key to evaluating the performance of your algorithm later on (and in cross validating multiple algorithms against one another) \n",
    "* Training dataset- used to train the algorithm \n",
    "* Testing dataset- used to evaluate accuracy of algorithm\n",
    "\n",
    "### Is my dataset large enough to split and train? \n",
    "The key question here is whether your dataset has enough entries that represent all possibilities that the model may encounter when applied to some unknown set of features. \n",
    "If our training dataset represents overwhelmingly edible mushrooms and we encounter a poisonous one can we trust that the algorithm will accurately categorize this outcome?\n",
    "\n",
    "### What is a general percentage to aim for? \n",
    "How much of my dataset should be split into testing and training?\n",
    "\n",
    "What do I do when my dataset is too small?\n",
    "K-fold cross validation may be a way to avoid being too optimistic in your fit. Resources on this are available here (https://machinelearningmastery.com/k-fold-cross-validation/)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#first we split our dataset into the X input (mushroom features) and y response (edibility) variables \n",
    "\n",
    "X = mushrooms.drop('class_1', axis = 1)\n",
    "y = mushrooms['class_1']\n",
    "\n",
    "#Here we take 20% of the dataset to test with, and train with the leftover 80%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#Take some time here to view and split the wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction using PCA \n",
    "\n",
    "*What elements of our dataset account for the most variation?*\n",
    "\n",
    "One way we can answer these questions is by performing a **Principal Component Analysis (PCA)**\n",
    "\n",
    "PCA is an unsupervised clustering method that can show you what features account for the greatest variability in your dataset, allowing you to condense your dataset into a set of 2 or 3 features (genes, treatments, traits) to feed into your algorithm. (Granted that your dataset can condense to these plot-able dimensions). PCA is a feature extraction technique that can aid in identifying those that best predict your dependent/response variable.\n",
    "\n",
    "One thing to be aware of, is that PCA will completely ignore the classifications of your data. It is unsupervised, it simply tries to capture the greatest variability in your dataset that it can with a particular number of dimensions. It will do this even if the feature with the greatest variability tells you nothing about the classifications you want to predict. Usually this is fine, as features with greater variability tend to be good for classification, but it’s not always the case.\n",
    "\n",
    "PCA, in comparison to methods that will pick out a subset of your features for your classification, brings you an unusual trade-off. To understand this trade-off, take a look at this PCA diagram.\n",
    "\n",
    "\n",
    "![](http://upload.wikimedia.org/wikipedia/commons/f/f5/GaussianScatterPCA.svg)\n",
    "\n",
    "The X and Y axes are our original features. The bold black arrows are the dimensions PCA might select on this data. Notice that they are running on diagonals; they are offset from the original dimensions. This is normal for PCA - PCA will tend to mish-mash the features of your original dataset together.\n",
    "\n",
    "A benefit of this, is that typically all of your features are accounted for to some degree. However, this comes at a cost; when you use PCA, it can make your results difficult to interpret - you won’t generally know which features were most important for your classification, if you run a classifier on the PCA-ed data.\n",
    "\n",
    "Also important when using PCA, is to remember that it will find the greatest variance. This means units are important, and can affect the result. If you pick a smaller unit for a dimension; maybe you use grams instead of kilograms, then all of your values in that dimension become much farther apart. PCA will then likely try harder to capture that dimension, even if that’s not what it should be doing - so you should be careful that all of your features are in roughly the same range of numerical values.\n",
    "\n",
    "\n",
    "\n",
    "Here we will break down our mushroom dataset into two principal components \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to start we need to scale our numeric dataset \n",
    "# so as not to overinflate the influence of a single feature in a different unit \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train_scl = sc.fit_transform(X_train)\n",
    "X_test_scl = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.02149</td>\n",
       "      <td>-0.783490</td>\n",
       "      <td>2.906238</td>\n",
       "      <td>-0.06459</td>\n",
       "      <td>-0.913412</td>\n",
       "      <td>-0.02149</td>\n",
       "      <td>1.474225</td>\n",
       "      <td>-0.817125</td>\n",
       "      <td>-0.076691</td>\n",
       "      <td>2.103539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228690</td>\n",
       "      <td>-0.423917</td>\n",
       "      <td>1.009741</td>\n",
       "      <td>-0.517781</td>\n",
       "      <td>-0.598738</td>\n",
       "      <td>-0.341565</td>\n",
       "      <td>-0.193262</td>\n",
       "      <td>-0.402219</td>\n",
       "      <td>-0.215335</td>\n",
       "      <td>-0.161400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.02149</td>\n",
       "      <td>-0.783490</td>\n",
       "      <td>-0.344087</td>\n",
       "      <td>-0.06459</td>\n",
       "      <td>1.094796</td>\n",
       "      <td>-0.02149</td>\n",
       "      <td>1.474225</td>\n",
       "      <td>-0.817125</td>\n",
       "      <td>-0.076691</td>\n",
       "      <td>-0.475389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228690</td>\n",
       "      <td>-0.423917</td>\n",
       "      <td>1.009741</td>\n",
       "      <td>-0.517781</td>\n",
       "      <td>-0.598738</td>\n",
       "      <td>-0.341565</td>\n",
       "      <td>-0.193262</td>\n",
       "      <td>2.486205</td>\n",
       "      <td>-0.215335</td>\n",
       "      <td>-0.161400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.02149</td>\n",
       "      <td>1.276341</td>\n",
       "      <td>-0.344087</td>\n",
       "      <td>-0.06459</td>\n",
       "      <td>-0.913412</td>\n",
       "      <td>-0.02149</td>\n",
       "      <td>-0.678322</td>\n",
       "      <td>1.223803</td>\n",
       "      <td>-0.076691</td>\n",
       "      <td>2.103539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228690</td>\n",
       "      <td>-0.423917</td>\n",
       "      <td>1.009741</td>\n",
       "      <td>-0.517781</td>\n",
       "      <td>-0.598738</td>\n",
       "      <td>2.927700</td>\n",
       "      <td>-0.193262</td>\n",
       "      <td>-0.402219</td>\n",
       "      <td>-0.215335</td>\n",
       "      <td>-0.161400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.02149</td>\n",
       "      <td>1.276341</td>\n",
       "      <td>-0.344087</td>\n",
       "      <td>-0.06459</td>\n",
       "      <td>-0.913412</td>\n",
       "      <td>-0.02149</td>\n",
       "      <td>-0.678322</td>\n",
       "      <td>-0.817125</td>\n",
       "      <td>-0.076691</td>\n",
       "      <td>-0.475389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228690</td>\n",
       "      <td>-0.423917</td>\n",
       "      <td>1.009741</td>\n",
       "      <td>-0.517781</td>\n",
       "      <td>-0.598738</td>\n",
       "      <td>-0.341565</td>\n",
       "      <td>-0.193262</td>\n",
       "      <td>-0.402219</td>\n",
       "      <td>-0.215335</td>\n",
       "      <td>-0.161400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.02149</td>\n",
       "      <td>-0.783490</td>\n",
       "      <td>-0.344087</td>\n",
       "      <td>-0.06459</td>\n",
       "      <td>-0.913412</td>\n",
       "      <td>-0.02149</td>\n",
       "      <td>-0.678322</td>\n",
       "      <td>1.223803</td>\n",
       "      <td>-0.076691</td>\n",
       "      <td>-0.475389</td>\n",
       "      <td>...</td>\n",
       "      <td>4.372727</td>\n",
       "      <td>-0.423917</td>\n",
       "      <td>-0.990353</td>\n",
       "      <td>-0.517781</td>\n",
       "      <td>-0.598738</td>\n",
       "      <td>-0.341565</td>\n",
       "      <td>5.174312</td>\n",
       "      <td>-0.402219</td>\n",
       "      <td>-0.215335</td>\n",
       "      <td>-0.161400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>-0.02149</td>\n",
       "      <td>-0.783490</td>\n",
       "      <td>-0.344087</td>\n",
       "      <td>-0.06459</td>\n",
       "      <td>1.094796</td>\n",
       "      <td>-0.02149</td>\n",
       "      <td>-0.678322</td>\n",
       "      <td>1.223803</td>\n",
       "      <td>-0.076691</td>\n",
       "      <td>-0.475389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228690</td>\n",
       "      <td>-0.423917</td>\n",
       "      <td>1.009741</td>\n",
       "      <td>-0.517781</td>\n",
       "      <td>-0.598738</td>\n",
       "      <td>-0.341565</td>\n",
       "      <td>-0.193262</td>\n",
       "      <td>2.486205</td>\n",
       "      <td>-0.215335</td>\n",
       "      <td>-0.161400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>-0.02149</td>\n",
       "      <td>-0.783490</td>\n",
       "      <td>2.906238</td>\n",
       "      <td>-0.06459</td>\n",
       "      <td>-0.913412</td>\n",
       "      <td>-0.02149</td>\n",
       "      <td>-0.678322</td>\n",
       "      <td>1.223803</td>\n",
       "      <td>-0.076691</td>\n",
       "      <td>2.103539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228690</td>\n",
       "      <td>-0.423917</td>\n",
       "      <td>-0.990353</td>\n",
       "      <td>-0.517781</td>\n",
       "      <td>-0.598738</td>\n",
       "      <td>-0.341565</td>\n",
       "      <td>-0.193262</td>\n",
       "      <td>-0.402219</td>\n",
       "      <td>-0.215335</td>\n",
       "      <td>6.195795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>-0.02149</td>\n",
       "      <td>1.276341</td>\n",
       "      <td>-0.344087</td>\n",
       "      <td>-0.06459</td>\n",
       "      <td>-0.913412</td>\n",
       "      <td>-0.02149</td>\n",
       "      <td>-0.678322</td>\n",
       "      <td>1.223803</td>\n",
       "      <td>-0.076691</td>\n",
       "      <td>-0.475389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228690</td>\n",
       "      <td>-0.423917</td>\n",
       "      <td>-0.990353</td>\n",
       "      <td>1.931317</td>\n",
       "      <td>-0.598738</td>\n",
       "      <td>-0.341565</td>\n",
       "      <td>-0.193262</td>\n",
       "      <td>2.486205</td>\n",
       "      <td>-0.215335</td>\n",
       "      <td>-0.161400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6497</th>\n",
       "      <td>-0.02149</td>\n",
       "      <td>-0.783490</td>\n",
       "      <td>2.906238</td>\n",
       "      <td>-0.06459</td>\n",
       "      <td>-0.913412</td>\n",
       "      <td>-0.02149</td>\n",
       "      <td>1.474225</td>\n",
       "      <td>-0.817125</td>\n",
       "      <td>-0.076691</td>\n",
       "      <td>2.103539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228690</td>\n",
       "      <td>-0.423917</td>\n",
       "      <td>1.009741</td>\n",
       "      <td>-0.517781</td>\n",
       "      <td>-0.598738</td>\n",
       "      <td>-0.341565</td>\n",
       "      <td>-0.193262</td>\n",
       "      <td>2.486205</td>\n",
       "      <td>-0.215335</td>\n",
       "      <td>-0.161400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6498</th>\n",
       "      <td>-0.02149</td>\n",
       "      <td>-0.783490</td>\n",
       "      <td>2.906238</td>\n",
       "      <td>-0.06459</td>\n",
       "      <td>-0.913412</td>\n",
       "      <td>-0.02149</td>\n",
       "      <td>-0.678322</td>\n",
       "      <td>-0.817125</td>\n",
       "      <td>-0.076691</td>\n",
       "      <td>-0.475389</td>\n",
       "      <td>...</td>\n",
       "      <td>4.372727</td>\n",
       "      <td>-0.423917</td>\n",
       "      <td>-0.990353</td>\n",
       "      <td>-0.517781</td>\n",
       "      <td>1.670181</td>\n",
       "      <td>-0.341565</td>\n",
       "      <td>-0.193262</td>\n",
       "      <td>-0.402219</td>\n",
       "      <td>-0.215335</td>\n",
       "      <td>-0.161400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6499 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2        3         4        5         6   \\\n",
       "0    -0.02149 -0.783490  2.906238 -0.06459 -0.913412 -0.02149  1.474225   \n",
       "1    -0.02149 -0.783490 -0.344087 -0.06459  1.094796 -0.02149  1.474225   \n",
       "2    -0.02149  1.276341 -0.344087 -0.06459 -0.913412 -0.02149 -0.678322   \n",
       "3    -0.02149  1.276341 -0.344087 -0.06459 -0.913412 -0.02149 -0.678322   \n",
       "4    -0.02149 -0.783490 -0.344087 -0.06459 -0.913412 -0.02149 -0.678322   \n",
       "...       ...       ...       ...      ...       ...      ...       ...   \n",
       "6494 -0.02149 -0.783490 -0.344087 -0.06459  1.094796 -0.02149 -0.678322   \n",
       "6495 -0.02149 -0.783490  2.906238 -0.06459 -0.913412 -0.02149 -0.678322   \n",
       "6496 -0.02149  1.276341 -0.344087 -0.06459 -0.913412 -0.02149 -0.678322   \n",
       "6497 -0.02149 -0.783490  2.906238 -0.06459 -0.913412 -0.02149  1.474225   \n",
       "6498 -0.02149 -0.783490  2.906238 -0.06459 -0.913412 -0.02149 -0.678322   \n",
       "\n",
       "            7         8         9   ...        85        86        87  \\\n",
       "0    -0.817125 -0.076691  2.103539  ... -0.228690 -0.423917  1.009741   \n",
       "1    -0.817125 -0.076691 -0.475389  ... -0.228690 -0.423917  1.009741   \n",
       "2     1.223803 -0.076691  2.103539  ... -0.228690 -0.423917  1.009741   \n",
       "3    -0.817125 -0.076691 -0.475389  ... -0.228690 -0.423917  1.009741   \n",
       "4     1.223803 -0.076691 -0.475389  ...  4.372727 -0.423917 -0.990353   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6494  1.223803 -0.076691 -0.475389  ... -0.228690 -0.423917  1.009741   \n",
       "6495  1.223803 -0.076691  2.103539  ... -0.228690 -0.423917 -0.990353   \n",
       "6496  1.223803 -0.076691 -0.475389  ... -0.228690 -0.423917 -0.990353   \n",
       "6497 -0.817125 -0.076691  2.103539  ... -0.228690 -0.423917  1.009741   \n",
       "6498 -0.817125 -0.076691 -0.475389  ...  4.372727 -0.423917 -0.990353   \n",
       "\n",
       "            88        89        90        91        92        93        94  \n",
       "0    -0.517781 -0.598738 -0.341565 -0.193262 -0.402219 -0.215335 -0.161400  \n",
       "1    -0.517781 -0.598738 -0.341565 -0.193262  2.486205 -0.215335 -0.161400  \n",
       "2    -0.517781 -0.598738  2.927700 -0.193262 -0.402219 -0.215335 -0.161400  \n",
       "3    -0.517781 -0.598738 -0.341565 -0.193262 -0.402219 -0.215335 -0.161400  \n",
       "4    -0.517781 -0.598738 -0.341565  5.174312 -0.402219 -0.215335 -0.161400  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6494 -0.517781 -0.598738 -0.341565 -0.193262  2.486205 -0.215335 -0.161400  \n",
       "6495 -0.517781 -0.598738 -0.341565 -0.193262 -0.402219 -0.215335  6.195795  \n",
       "6496  1.931317 -0.598738 -0.341565 -0.193262  2.486205 -0.215335 -0.161400  \n",
       "6497 -0.517781 -0.598738 -0.341565 -0.193262  2.486205 -0.215335 -0.161400  \n",
       "6498 -0.517781  1.670181 -0.341565 -0.193262 -0.402219 -0.215335 -0.161400  \n",
       "\n",
       "[6499 rows x 95 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_scl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2) #create PCA class object\n",
    "\n",
    "pca.fit_transform(X_train_scl) \n",
    "X_train_pca = pca.transform(X_train_scl) #perform PCA on training dataset \n",
    "X_test_pca = pca.transform(X_test_scl) #apply PCA transformation to scaled test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape:    (6499, 95)\n",
      "transformed shape: (6499, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"original shape:   \", X_train.shape)\n",
    "print(\"transformed shape:\", X_train_pca.shape) #what are the effects of dimensionality redution for this dataset?\n",
    "scatter = plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], alpha=0.8, c = y_train)\n",
    "plt.axis('equal');\n",
    "handles, labels = scatter.legend_elements(prop=\"colors\", alpha=0.6)\n",
    "legend = plt.legend(handles, labels, loc=\"upper right\", title=\"edibility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#what if we dont know the number of components that make up variability in our dataset?\n",
    "pca_n = PCA()\n",
    "pca_n = pca_n.fit(X_train_scl)\n",
    "variance = pca_n.explained_variance_ratio_[0:7]\n",
    "variance\n",
    "df = pd.DataFrame({'var':variance,\n",
    "             'PC':['PC1','PC2','PC3','PC4','PC5', 'PC6','PC7']})\n",
    "scree = plt.bar(df[\"PC\"],df['var'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform PCA on your dataset\n",
    "Take some time now to perform PCA on your wine training dataset.\n",
    "\n",
    "How many components account for the highest variability in your data? Prepare a scree plot that shows this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running different classification algorithms \n",
    "There is no single classifier that will always perform best on your dataset. Because of this we run multiple algorithms on our training dataset and evaluate their predictive scores against one another. \n",
    "In this tutorial we will use:\n",
    "1. Logistic Regression\n",
    "1. Support Vector Machine \n",
    "1. K- Nearest Neighbor Model\n",
    "1. Decision Tree\n",
    "1. Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "This algorithm fits a “logistic function” to a dataset of true and false values. Here’s an example of a logistic function. Notice how it doesn’t go higher than 1 or lower than 0 - the fit done with logistic regression will always give a fit like this.\n",
    "\n",
    "![](https://st4.ning.com/topology/rest/1.0/file/get/2808358994?profile=original)\n",
    "\n",
    "* When we fit this function, it doesn’t actually give us a classification - it suggests a probability that the correct class is one class or the other. We have to choose a cut-off.\n",
    "\n",
    "* One thing to note about Logistic regression, is that, when we do it in higher dimensional spaces, these cut-offs we choose will always be a straight line. For example, take a look at this data-set and a hypothetical decision boundary found with logistic regression:\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"logistic_regression_example.png\" width=\"500\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "def print_score(classifier,X_train,y_train,X_test,y_test,train=True):\n",
    "    if train == True:\n",
    "        print(\"Training results:\\n\")\n",
    "        print('Accuracy Score: {0:.4f}\\n'.format(accuracy_score(y_train,classifier.predict(X_train))))\n",
    "        print('Classification Report:\\n{}\\n'.format(classification_report(y_train,classifier.predict(X_train))))\n",
    "        print('Confusion Matrix:\\n{}\\n'.format(confusion_matrix(y_train,classifier.predict(X_train))))\n",
    "        res = cross_val_score(classifier, X_train, y_train, cv=10, n_jobs=-1, scoring='accuracy')\n",
    "        print('Average Accuracy:\\t{0:.4f}\\n'.format(res.mean()))\n",
    "        print('Standard Deviation:\\t{0:.4f}'.format(res.std()))\n",
    "    elif train == False:\n",
    "        print(\"Test results:\\n\")\n",
    "        print('Accuracy Score: {0:.4f}\\n'.format(accuracy_score(y_test,classifier.predict(X_test))))\n",
    "        print('Classification Report:\\n{}\\n'.format(classification_report(y_test,classifier.predict(X_test))))\n",
    "        print('Confusion Matrix:\\n{}\\n'.format(confusion_matrix(y_test,classifier.predict(X_test))))\n",
    "\n",
    "#we should break this function down to each component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9060\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x7f917451da90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXRV9dn28e9NEiCEEKagMiMiikxKFFEoYBVR7LJYBaU+KtVafNT66sIXHCr1sa3YWkutA1oFtb4FZ6uIaEUUbfFh0AgyaQTECGIAGcKc5H7/OCdpyEBOIOfsJPv6rHVWzh7PvUM41x5/P3N3REQkvBoEXYCIiARLQSAiEnIKAhGRkFMQiIiEnIJARCTkkoMuoLpat27tnTt3DroMEZE6ZcmSJZvdPbOiaXUuCDp37szixYuDLkNEpE4xs68qm6ZTQyIiIacgEBEJOQWBiEjIKQhEREJOQSAiEnJxCwIzm2Zm35nZZ5VMNzN70MxyzGypmZ0Sr1pERKRy8TwieAoYfojp5wHdoq9rgUfjWIuIiFQibs8RuPt8M+t8iFkuBJ7xSDvYH5lZczM7xt03xqOe1d/u5I2lG+KxapGES2+cwtgzO5OcpLO7cuSCfKCsHfB1qeHc6LhyQWBm1xI5aqBjx46H9WE53+Xzl3k5h7WsSG1S3IXI9H+tpUfbDMBxBwfcPfrzP8PFy3RomcrvRvbCzEqtyylyMKBBA0PCKcggqOivrsJectz9ceBxgKysrMPqSWdE72MY0XvE4SwqUqt89s12LvjLhwB8s20PBphFX1j0Z2Rk8bRP1m8DYMbCr0lqYBS5U7ZPqr9ekcVpXVqSkZqSyM2RWiDIIMgFOpQabg/o3I1IFXq2y2Dd5Ort1KzcuINLH/+In/bviBk0MMPMaGAw5Z0vAPj5M5GmWy4/vSOFRU5hkdMoOYnx53ZXONRzFs+uKqPXCGa5e88Kpo0AbgDOB/oDD7r7aVWtMysry9XWkEjN2VdQyPur87j2b0sAaJXWkAYNjLyd+0rmSWuYREGRs6+giKHdMxmV1YFjM5vS/ej0oMqWajKzJe6eVeG0eAWBmc0AhgCtgU3AJCAFwN2nWuRE5UNE7izaDYx19yq/4RUEIomx90AhJ/xqDhf3a0/z1BSSkozH3l9z0Dzn9DiKgsIiCoqcA4VF7NlfyOnHtmL0qR3o0LIJKbqYXWsEEgTxoiAQCc6Xefnk7dzHHa8s48u8XTRrnEynVmkkJxkpDRqwcN3Wg+b/+aAumBlXD+zCUc0aB1S1gIJARBJk/ud5vLc6j2n/WgtA45QG7D1QxODjM/lJv/ZkpKYw+PgKm8SXOFMQiEggvt+1n5Pv+edB4z667YccnaGjg0Q7VBDUuY5pRKTuaJHWkBfGDaBhUgMeeS+Ht5Zv4vR753L1wC7sPVBIYZEz9swutGrakBZNGpKkZxkCoSMCEUmI/H0F9Jz0VslwA4OiMl8/N551HNf+4FjSG+t21ZqmU0MiUisUf98UP938s6cW0blVWsk1hWK3ntudTq2acEHvtgmvsb5SEIhIrVdY5HS9ffZB4y7p154BXVtxXs9jSG2YFFBl9YOCQETqBHdn6679vLvqO259cWm56RmpKdww9DjWbM6nScNk8vcW0Kt9BueedDSZ6Y0CqLjuUBCISJ2zcuMOGphx7pT5nNKxOR9H20uqzN+v6c8Zx7VOUHV1j4JAROq8PfsL2bRjL63TG5GakkRSA+PNZRv5y7s5rNi4A4CRJ7ejoMjp2DKVW87prruQSlEQiEi95e50uW12hdNO69yS/YVFTL/qVFqkNUxwZbWLgkBEQmPJV9/zk0f/XW78qnuG0zglvBecDxUEahFKROqVfp1asG7yCNZNHsHCO35YMv4RdUxVKQWBiNRbbdIbs/J/Il2nJzXQ111l9JsRkXqtUXLka+4v734RcCW1l4JAROq14i6aC4qcpbmHvgU1rBQEIlKvmRm//GE3AG5+LjvgamonBYGI1Hs3nx0Jgi/zdgVcSe2kIBCReq+4kTuAXfsKAqykdlIQiEgo3H7+CUGXUGspCEREQk5BICIScgoCEQmFr7bsBuDPc/U8QVkKAhEJhVbRRucen7+GL/PyA66mdlEQiEgo3DKsO7ee2x2AHXsOBFxN7aIgEJHQaN00clTw9opNAVdSuygIRCQ0sjq3BGCtHiw7iIJAREKja2ZTAOYs/zbgSmoXBYGISMgpCEQkVH551nGYujI+SFyDwMyGm9lqM8sxs4kVTG9hZq+Y2VIzW2hmPeNZj4iIlBe3IDCzJOBh4DygB3CZmfUoM9vtQLa79wauAP4cr3pERKRi8TwiOA3Icfc17r4fmAlcWGaeHsBcAHdfBXQ2s6PiWJOIiJQRzyBoB3xdajg3Oq60T4GLAMzsNKAT0L7siszsWjNbbGaL8/Ly4lSuiEg4xTMIKroc42WGJwMtzCwbuBH4BCjXWLi7P+7uWe6elZmZWfOVioiEWHIc150LdCg13B7YUHoGd98BjAWwSM8Ra6MvERFJkHgeESwCuplZFzNrCFwKvFZ6BjNrHp0GcA0wPxoOIiKSIHE7InD3AjO7AXgLSAKmuftyMxsXnT4VOBF4xswKgRXA1fGqR0REKhbPU0O4+2xgdplxU0u9XwB0i2cNIiJyaHqyWERCZcuu/birE/vSFAQiEir/ytkMwKylG6qYMzwUBCISKtPHngbAhJeWBVxJ7aEgEJFQ6dI6reS9e9lHm8JJQSAioXXN04uDLqFWUBCISOgsuuNsAOau+i7gSmoHBYGIhE5meiOOzUyresaQUBCISCgNOb4N6Y3i+ihVnaEgEBEJOQWBiIRSQVERO/cV6M4hFAQiElLPLPgKgA+jD5iFmYJARELpsf/qB8DOvWpqQkEgIqHUJr0RAP/vf78KuJLgKQhEJJSKnzD+V84WFq7dGnA1wVIQiEgoNW/SsORZgrmrNgVcTbAUBCISWnNvGQxAakpSwJUES0EgIhJyCgIRkZBTEIhI6M357NugSwiUgkBEQm/VtzuDLiFQCgIRCS0zY1RWe47JaBx0KYFSEIiIhJyCQEQk5BQEIiIhpyAQkVB7c9m3bNy+l0079gZdSmAUBCISau1bNgFgdYjvHFIQiEio3TniRAA+WrMl4EqCoyAQkVBr3iQFgLeWh/ehMvXcLCKhdlLbDI5r05TuR6UHXUpgdEQgIhJycQ0CMxtuZqvNLMfMJlYwPcPMXjezT81suZmNjWc9IiJSXtyCwMySgIeB84AewGVm1qPMbNcDK9y9DzAE+KOZNYxXTSIiUl48jwhOA3LcfY277wdmAheWmceBdDMzoCmwFVBP0iIiCRTPIGgHfF1qODc6rrSHgBOBDcAy4CZ3Lyq7IjO71swWm9nivLy8eNUrIhJK8QwCq2Cclxk+F8gG2gJ9gYfMrFm5hdwfd/csd8/KzMys+UpFREIsnkGQC3QoNdyeyJ5/aWOBlz0iB1gLnBDHmkREpIyYgsDMzjSzf5rZ52a2xszWmtmaKhZbBHQzsy7RC8CXAq+VmWc98MPoZxwFdAeqWq+IiNSgWB8oexK4GVgCFMaygLsXmNkNwFtAEjDN3Zeb2bjo9KnAPcBTZraMyKmkCe6+uZrbICIiRyDWINju7m9Wd+XuPhuYXWbc1FLvNwDDqrteERGpObEGwTwz+wPwMrCveKS7fxyXqkREJGFiDYL+0Z9ZpcY5cFbNliMiIokWUxC4+9B4FyIiIsGI9a6hDDN7oPihLjP7o5llxLs4ERGJv1ifI5gG7ARGRV87gOnxKkpERBIn1msEXd39J6WG7zaz7HgUJCIiiRXrEcEeMxtYPGBmZwJ74lOSiIgkUqxHBNcBT0evCxiRVkKvildRIiKSOLHeNZQN9CluEM7dd8S1KhGRBMr5Lp+c7/J5yJ1Iq/jhcsggMLPL3f1ZM7ulzHgA3P2BONYmIpJQ+fsKSG+cEnQZCVfVNYK06M/0Sl4iInXenSNODLqEQB3yiMDdH4v+vDsx5YiISKLF+kDZ782smZmlmNlcM9tsZpfHuzgREYm/WG8fHRa9QHwBkQ5njgdujVtVIiKSMLEGQfHVk/OBGe6+NU71iIgknEc70S3bl25YxBoEr5vZKiKtj841s0xgb/zKEhFJnFnLNgLwj+yyvemGQ0xB4O4TgQFAlrsfAHYBF8azMBGRRPndyJ4A7DsQUweM9U5VzxGc5e7vmtlFpcaVnuXleBUmIpIoHVo2CbqEQFX1ZPFg4F3gRxVMcxQEIiJ1XlXPEUyK/hybmHJERCTRYn2O4Hdm1rzUcAsz+038yhIRkUSJ9a6h89x9W/GAu39P5FZSERGp42INgiQza1Q8YGapQKNDzC8iInVErP0RPEvk+YHpRC4S/wx4Om5ViYhIwsTaH8HvzWwpcDaRjmnucfe34lqZiIgkRKxHBAArgQJ3f8fMmphZurvvjFdhIiKSGLHeNfRz4EXgseiodsCr8SpKRCQIRR7O1oZivVh8PXAmsAPA3b8A2sSrKBGRRPKiyM/fzV4VbCEBiTUI9rn7/uIBM0smvA31iUg9k9EkfN1TlhZrELxvZrcDqWZ2DvAC8HpVC5nZcDNbbWY5Zjaxgum3mll29PWZmRWaWcvqbYKIyJFLbxy5ZLpnf/ganos1CCYAecAy4BfAbODOQy1gZknAw8B5QA/gMjPrUXoed/+Du/d1977AbcD76utARIKwc28BACs27gi4ksSrMgjMrAGwzN3/6u6XuPvF0fdVnRo6Dchx9zXR00ozOXTT1ZcBM2KuXESkBk0feyoAu/YVBFxJ4lUZBO5eBHxqZh2rue52wNelhnOj48oxsybAcOClSqZfa2aLzWxxXl5eNcsQEana11t3A/DAPz8PuJLEi/XU0DHA8mjH9a8Vv6pYxioYV9lRxI+Af1V2WsjdH3f3LHfPyszMjLFkEZHYXd6/EwDdj0oPuJLEi/WBsrsPY925QIdSw+2ByvqBuxSdFhKRADVoENl3fW7x19x3ce+Aq0msqnooawyMA44jcqH4SXeP9QTaIqCbmXUBviHyZT+mgs/IINIBzuXVqFtERGpIVaeGnibSYf0yInf//DHWFUcD4wbgLSLNUzzv7svNbJyZjSs160jgbXffVa3KRURq2E0/7BZ0CYGo6tRQD3fvBWBmTwILq7Nyd59N5FbT0uOmlhl+CniqOusVEZGaU9URwYHiN9U4JSQiInVIVUcEfcys+OkKI/Jk8Y7oe3f3ZnGtTkRE4q6qzuuTElWIiIgEI9bnCEREpJ5SEIiIhJyCQEQk5BQEIiIhpyAQEQk5BYGISMgpCEREonbvjzw3u7+gKOBKEktBICIS9eKSXACunFat1nTqPAWBiEjUq9efCcCCNVsCriSxYu2PQESk3uvUKo1B3VqTH7LuKnVEICIScgoCEZGQUxCIiIScrhGIiJSy5Kvv2b2/kKIiL+nHuL7TEYGISCm79xcCsGZzfsCVJI6CQESklIfHnAJAkQdcSAIpCEREQk5BICIScgoCEZFSvtm2G4B/52wOuJLEURCIiJRy/FHpAMxbnRdwJYmjIBARKWVI9zYAvP95HrOWbgi4msRQEIiIVOKGv3+Ce/2/fUhBICJSxrrJI0ref7tjb4CVJIaCQESkAvf9pBcAITggUBCIiISdgkBEpAIL134PwCuffBNwJfEX1yAws+FmttrMcsxsYiXzDDGzbDNbbmbvx7MeEZFY/WxgZwD2HigMtpAEiFvro2aWBDwMnAPkAovM7DV3X1FqnubAI8Bwd19vZm3iVY+ISHWc1DYDALP63wJpPI8ITgNy3H2Nu+8HZgIXlplnDPCyu68HcPfv4liPiIhUIJ5B0A74utRwbnRcaccDLczsPTNbYmZXVLQiM7vWzBab2eK8vPA87ScikgjxDIKKjqfK3oiVDPQDRgDnAr8ys+PLLeT+uLtnuXtWZmZmzVcqIlKJB+d+EXQJcRfPHspygQ6lhtsDZZ/XzgU2u/suYJeZzQf6AJ/HsS4RESklnkcEi4BuZtbFzBoClwKvlZnnH8AgM0s2syZAf2BlHGsSEYnZ6KwOHN2scdBlxF3cjgjcvcDMbgDeApKAae6+3MzGRadPdfeVZjYHWAoUAU+4+2fxqklEpDoOFBaFookJq2sNKmVlZfnixYuDLkNEQqDzxDdK3n/8q3NomdYwwGqOjJktcfesiqbpyWIRkUo8ccV/vjdnLlofYCXxpSAQEanE2T2O4tO7hgGQ0qD+fl3W3y0TEakJ0Rvhfzu7/t7HoiAQETmEjNSUoEuIOwWBiEgVhnSPPMi6r6B+NkCnIBARqcJ70Y7sr5y2MOBK4kNBICJShRfGDQCgfYsmAVcSHwoCEZEqnNq5JW0zGlfYgFp9oCAQEYnBhu17eWFJbtBlxIWCQESkGupaawyxUBCIiMTg/5zdLegS4kZBICIScgoCEZEYrNu8C4Dvdu4LuJKapyAQEYnBui27AZi3qv51ra4gEBGJwUNjTgbg9leWBVxJzVMQiIjEoHmTSF8ERR7pp+CR93LqzR1ECgIRkRg0bZTMtT84tmT493NWc9+c1QFWVHMUBCIiMbr9/BN586ZBnNa5JQANk+rHs8YKAhGRajjxmGY8P24AVj8yAFAQiIiEnoJARCTkFAQiIofBHR58NyfoMmqEgkBE5AgMnzKfoqK6fRupgkBE5DDc9MNII3Srvt3JjEXrA67myCgIREQOw83nHM8l/doD8MHnmwOu5sgoCEREDtM9P+4JwJzl3wZcyZFJDrqAmnDgwAFyc3PZu3dv0KWIJETjxo1p3749KSkpQZcSao1Tkjjh6HTy9xUEXcoRqRdBkJubS3p6Op07d8bq01MeIhVwd7Zs2UJubi5dunQJupzQW/XtTgC+27GXNs0aB1zN4akXp4b27t1Lq1atFAISCmZGq1atdARcS7RrngrAV1t3B1zJ4YtrEJjZcDNbbWY5ZjaxgulDzGy7mWVHX3cdwWcdWbEidYj+3muP346MXCf4dnvdDea4nRoysyTgYeAcIBdYZGavufuKMrN+4O4XxKsOEZF42rprPwA3zviEvh2a07Z5KkkN6lZQx/OI4DQgx93XuPt+YCZwYRw/L1BNmzY94nUsXryYX/7yl5VOX7duHX//+99jnh+gc+fO9OrVi969ezN48GC++uqrI66zpkydOpVnnnmmRta1ceNGLrjg4P2Jm266iXbt2lFUVFQy7qmnniIzM5O+ffvSo0cP/vrXvx7xZ69du5b+/fvTrVs3Ro8ezf79+yucb8KECfTs2ZOePXvy3HPPlYy/+uqr6dOnD7179+biiy8mPz8fgFmzZjFp0qQjrk/i66JT2pe8H/T7eXS9fTZ/+6j2/D+LibvH5QVcDDxRavi/gIfKzDME2AJ8CrwJnFTVevv16+dlrVixoty4REtLS4v7Z8ybN89HjBhRrWU6derkeXl57u5+1113+TXXXHPEdRQVFXlhYeERr6cmjR8/3l999dWS4cLCQu/QoYP379/f582bVzJ++vTpfv3117u7+6ZNm7x169b+7bffHtFnX3LJJT5jxgx3d//FL37hjzzySLl5Zs2a5WeffbYfOHDA8/PzvV+/fr59+3Z395Kf7u4333yz33vvve4e+T337dvXd+3aVeHn1oa/e4n4w5xV3mnCrINem3fuDbqsgwCLvZLv1XjeNVTRsVHZ57A/Bjq5e76ZnQ+8CnQrtyKza4FrATp27HjID7379eWs2LDjsAquTI+2zZj0o5OqvVx2djbjxo1j9+7ddO3alWnTptGiRQsWLVrE1VdfTVpaGgMHDuTNN9/ks88+47333uP+++9n1qxZvP/++9x0001A5Hzw/PnzmThxIitXrqRv375ceeWVnHzyySXz5+fnc+ONN7J48WLMjEmTJvGTn/zkoHoGDBjAgw8+CEBeXh7jxo1j/frIE5FTpkzhzDPPJC8vjzFjxrBlyxZOPfVU5syZw5IlS8jPz+e8885j6NChLFiwgFdffZXnn3+e559/nn379jFy5Ejuvvtudu3axahRo8jNzaWwsJBf/epXjB49mokTJ/Laa6+RnJzMsGHDuP/++/n1r39N06ZNGT9+fKW/qyFDhtC/f3/mzZvHtm3bePLJJxk0aFC53/VLL73Eb37zm5LhefPm0bNnT0aPHs2MGTMYMmRIuWXatGlD165d+eqrrzjqqKOq/e8LkR2pd999t+RI7corr+TXv/4111133UHzrVixgsGDB5OcnExycjJ9+vRhzpw5jBo1imbNmpWsa8+ePSXn/82MIUOGMGvWLEaNGnVY9UlijD+3O+PP7c623fvp+z//BKDfb97h/kv6cHG/9lUsHbx4nhrKBTqUGm4PbCg9g7vvcPf86PvZQIqZtS67Ind/3N2z3D0rMzMzjiXXrCuuuIL77ruPpUuX0qtXL+6++24Axo4dy9SpU1mwYAFJSUkVLnv//ffz8MMPk52dzQcffEBqaiqTJ09m0KBBZGdnc/PNNx80/z333ENGRgbLli1j6dKlnHXWWeXWOWfOHH784x8DkdMmN998M4sWLeKll17immuuAeDuu+/mrLPO4uOPP2bkyJElQQGwevVqrrjiCj755BNWr17NF198wcKFC8nOzmbJkiXMnz+fOXPm0LZtWz799FM+++wzhg8fztatW3nllVdYvnw5S5cu5c4774z5dwVQUFDAwoULmTJlykHji61du5YWLVrQqFGjknEzZszgsssuY+TIkcyaNYsDBw6UW27NmjWsWbOG44477qDxq1evpm/fvhW+tm3bdtC8W7ZsoXnz5iQnR/ap2rdvzzfffFPus/r06cObb77J7t272bx5M/PmzePrr78umT527FiOPvpoVq1axY033lgyPisriw8++KDc+qR2at6kIS//9xklw+Nf+JRTf/tOgBXFJp5HBIuAbmbWBfgGuBQYU3oGMzsa2OTubmanEQmmLUfyoYez5x4P27dvZ9u2bQwePBiI7ClecsklbNu2jZ07d3LGGZE/ljFjxjBr1qxyy5955pnccsst/PSnP+Wiiy6ifftD71W88847zJw5s2S4RYsWJe+HDh3Kpk2baNOmTcle8zvvvMOKFf+5br9jxw527tzJhx9+yCuvvALA8OHDD1pPp06dOP300wF4++23efvttzn55EiH3vn5+XzxxRcMGjSI8ePHM2HCBC644AIGDRpEQUEBjRs35pprrmHEiBHlzuVX9rsqdtFFFwHQr18/1q1bV27bN27cSOkdhP379zN79mz+9Kc/kZ6eTv/+/Xn77bcZMWIEAM899xwffvghjRo14rHHHqNly5YHra979+5kZ2cf8vddzCvos7aiO3qGDRvGokWLOOOMM8jMzGTAgAEl4QEwffp0CgsLufHGG3nuuecYO3YsEDlq2bBhQ7n1Se11SscWrJs8gi63vYE75O3cR+eJbwAw9fJTGNbjaAqKnP2FRTRtVDse5YpbFe5eYGY3AG8BScA0d19uZuOi06cSuY5wnZkVAHuAS72i/1n1SKybN3HiREaMGMHs2bM5/fTTeeedQ+9VuHultxTOmzePtLQ0rrrqKu666y4eeOABioqKWLBgAampqTHXl5aWdtB8t912G7/4xS/KzbdkyRJmz57NbbfdxrBhw7jrrrtYuHAhc+fOZebMmTz00EO8++67h9ye0or39JOSkigoKP8EZ2pq6kH31M+ZM4ft27fTq1cvAHbv3k2TJk1KgmD06NE89NBDlX7e6tWrGT16dIXT3nvvPZo3b14y3Lp1a7Zt20ZBQQHJycnk5ubStm3bCpe94447uOOOO4DIDkC3bgefBU1KSmL06NH84Q9/KAmCvXv3lvs3krph7b0juOzxj1iw5j/7tuOe/TimZft3acmY/h0596SjaZxS8VmDmhTX5wjcfba7H+/uXd39t9FxU6MhgLs/5O4nuXsfdz/d3f8dz3oSKSMjgxYtWpQc1v/tb39j8ODBtGjRgvT0dD766COAg/biS/vyyy/p1asXEyZMICsri1WrVpGens7OnTsrnH/YsGEHfbl9//33B01PTU1lypQpPPPMM2zdurXc/MV7wAMHDuT5558HInv9ZddT7Nxzz2XatGkld7h88803fPfdd2zYsIEmTZpw+eWXM378eD7++GPy8/PZvn07559/PlOmTCm3t13Z7ypWxx9//EFHCjNmzOCJJ55g3bp1rFu3jrVr1/L222+ze3dsD/wUHxFU9CodAhDZ+x86dCgvvvgiAE8//TQXXlj+5rjCwkK2bIl8ISxdupSlS5cybNgw3J2cnEib9u7O66+/zgknnFCy3Oeff07Pnj1j/l1I7TLj2tNZN3kEs24cSMeWTWJe7n/XbuWmmdmc8Ks5dJ74Bp0nvsELi7+uesHDVDuOS+qB3bt3H3T65pZbbuHpp58uuQB67LHHMn36dACefPJJfv7zn5OWlsaQIUPIyMgot74pU6Ywb948kpKS6NGjB+eddx4NGjQoudB41VVXlZyWAbjzzju5/vrr6dmzJ0lJSUyaNKnklEqxY445hssuu4yHH36YBx98kOuvv57evXtTUFDAD37wA6ZOncqkSZO47LLLeO655xg8eDDHHHMM6enpJV/4xYYNG8bKlSsZMGAAELl99tlnnyUnJ4dbb72VBg0akJKSwqOPPsrOnTu58MIL2bt3L+7On/70p3LbW9nvKhZpaWl07dqVnJwc2rZty1tvvcVjjz120PSBAwfy+uuvx7zO6rjvvvu49NJLufPOOzn55JO5+uqrgcjtvVOnTuWJJ57gwIEDJRe5mzVrxrPPPktycjJFRUVceeWV7NixA3enT58+PProoyXrnjdvHvfee29c6pbE6dkug/n/d2jJsLuTv6+AB/75Oce2TmPFxp2MPrUDPY5pxrR/rWXym6vKrePWF5eyYM0WHhjVt8brs7p2JiYrK8sXL1580LiVK1dy4oknBlRR9eXn55c8dzB58mQ2btzIn//854Criti3bx9JSUkkJyezYMECrrvuupjPlwfplVdeYcmSJQfdOVTXbdq0iTFjxjB37twKp9e1v3upvg3b9rDkq+954J+fs3bzLv56RRbn9Di8O9zMbCzSjlYAAAX3SURBVIm7Z1U0TUcEAXjjjTe49957KSgooFOnTjz11FNBl1Ri/fr1jBo1iqKiIho2bFgjD1wlwsiRI0tOvdQX69ev549//GPQZUiA2jZPpW3zVH7Up+LrTjVFRwQidZT+7qU6DnVEUC9aH4XY78YRqQ/09y41qV4EQePGjdmyZYv+c0goeLQ/gsaN62bb91L71ItrBO3btyc3N5e8vLygSxFJiOIeykRqQr0IgpSUFPXUJCJymOrFqSERETl8CgIRkZBTEIiIhFyde47AzPKAw+3+pzWwuQbLqQu0zeGgbQ6HI9nmTu5eYTv+dS4IjoSZLa7sgYr6StscDtrmcIjXNuvUkIhIyCkIRERCLmxB8HjQBQRA2xwO2uZwiMs2h+oagYiIlBe2IwIRESlDQSAiEnL1MgjMbLiZrTazHDObWMF0M7MHo9OXmtkpQdRZk2LY5p9Gt3Wpmf3bzPoEUWdNqmqbS813qpkVmtnFiawvHmLZZjMbYmbZZrbczN5PdI01LYa/7Qwze93MPo1u89gg6qwpZjbNzL4zs88qmV7z31/uXq9eQBLwJXAs0BD4FOhRZp7zgTcBA04H/jfouhOwzWcALaLvzwvDNpea711gNnBx0HUn4N+5ObAC6BgdbhN03QnY5tuB+6LvM4GtQMOgaz+Cbf4BcArwWSXTa/z7qz4eEZwG5Lj7GnffD8wELiwzz4XAMx7xEdDczI5JdKE1qMptdvd/u/v30cGPgLrehnEs/84ANwIvAd8lsrg4iWWbxwAvu/t6AHev69sdyzY7kG5mBjQlEgQFiS2z5rj7fCLbUJka//6qj0HQDvi61HBudFx156lLqrs9VxPZo6jLqtxmM2sHjASmJrCueIrl3/l4oIWZvWdmS8zsioRVFx+xbPNDwInABmAZcJO7FyWmvEDU+PdXveiPoAyrYFzZe2RjmacuiXl7zGwokSAYGNeK4i+WbZ4CTHD3wsjOYp0XyzYnA/2AHwKpwAIz+8jdP493cXESyzafC2QDZwFdgX+a2QfuviPexQWkxr+/6mMQ5AIdSg23J7KnUN156pKYtsfMegNPAOe5+5YE1RYvsWxzFjAzGgKtgfPNrMDdX01MiTUu1r/tze6+C9hlZvOBPkBdDYJYtnksMNkjJ9BzzGwtcAKwMDElJlyNf3/Vx1NDi4BuZtbFzBoClwKvlZnnNeCK6NX304Ht7r4x0YXWoCq32cw6Ai8D/1WH9w5Lq3Kb3b2Lu3d2987Ai8B/1+EQgNj+tv8BDDKzZDNrAvQHVia4zpoUyzavJ3IEhJkdBXQH1iS0ysSq8e+vendE4O4FZnYD8BaROw6muftyMxsXnT6VyB0k5wM5wG4iexR1VozbfBfQCngkuodc4HW45cYYt7leiWWb3X2lmc0BlgJFwBPuXuFtiHVBjP/O9wBPmdkyIqdNJrh7nW2e2sxmAEOA1maWC0wCUiB+319qYkJEJOTq46khERGpBgWBiEjIKQhEREJOQSAiEnIKAhGRkFMQiFQg2lpptpl9Fm3ZsnkNr3+dmbWOvs+vyXWLVJeCQKRie9y9r7v3JNIA2PVBFyQSLwoCkaotINqol5l1NbM50QbdPjCzE6LjjzKzV6Jt4n9qZmdEx78anXe5mV0b4DaIVKrePVksUpPMLIlI8wVPRkc9Doxz9y/MrD/wCJHGzh4E3nf3kdFlmkbn/5m7bzWzVGCRmb1UD9p5knpGQSBSsVQzywY6A0uItGjZlEgHPy+Uas20UfTnWcAVAO5eCGyPjv+lmY2Mvu8AdAMUBFKrKAhEKrbH3fuaWQYwi8g1gqeAbe7eN5YVmNkQ4GxggLvvNrP3gMbxKVfk8OkagcghuPt24JfAeGAPsNbMLoGSvmOL+36eC1wXHZ9kZs2ADOD7aAicQKRbQZFaR0EgUgV3/4RIX7mXAj8FrjazT4Hl/KfbxJuAodEWMJcAJwFzgGQzW0qkhcyPEl27SCzU+qiISMjpiEBEJOQUBCIiIacgEBEJOQWBiEjIKQhEREJOQSAiEnIKAhGRkPv/vMPwutfc0RsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#precision recall curve + graphics for each classifier, frame in the context of \"would you eat this mushroom given your chosen classifier\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "classifier.fit(X_train_pca,y_train)\n",
    "print('Accuracy Score: {0:.4f}\\n'.format(accuracy_score(y_train,classifier.predict(X_train_pca))))\n",
    "\n",
    "# scikit learn has several functions to help with evaluating the accuracy of our model\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "plot_precision_recall_curve(classifier, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use any of the above algorithms on the wine dataset and discuss results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)\n",
    "\n",
    "* A support vector machine skips the parts with the logistic regression fit, and simply tries to stick a decision boundary into your dataset and the best possible place. It will often give very similar results to logistic regression.\n",
    "* However, most SVM implementations provide you with something called the “kernel trick.” You let it add more dimensions to your dataset, and those dimensions can be used to find better decision boundaries. \n",
    "\n",
    "Here’s what that can look like:\n",
    "\n",
    "![](https://miro.medium.com/max/2400/1*gXvhD4IomaC9Jb37tzDUVg.png)\n",
    "\n",
    "In our example datset that can look like: \n",
    "\n",
    "<div>\n",
    "<img src=\"svm_example.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "Worth mentioning; the decision boundaries aren’t limited to circles. This trick can also be used to get other types of curved boundaries; it depends partly on what you do to add more dimensions. Many libraries will handle this for you behind the scenes. \n",
    "You can also do this trick with Logistic Regression, but it’s less commonly done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors\n",
    "\n",
    "The idea behind K Nearest Neighbors is to identify K groupings of datapoints given their \"distance\" from one another. For each test point, look at the k nearest training points - these are its “neighbors.” We will then have those neighbors “vote” on how to classify the test point.\n",
    "\n",
    "This method is really good at picking up bizarre decision boundaries that are difficult to capture with other methods.\n",
    "\n",
    "This method can do poorly in areas where there are points coming from both classifications. For example, if a region of your feature space has a 60% chance of being a positive case, you probably want to mark this as positive, but 40% of your training points in that region will be negative, and it is very possible to end up near a cluster of negative neighbors and misclassify your test point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "A decision tree makes a tree of “decisions” that give greater and greater quality predictions. Here’s how it looks on our example dataset.\n",
    "\n",
    "<div>\n",
    "<img src=\"decision_tree_example.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "It deals with nonlinear situations much better than the logistic regression fit, but it’s still clearly not quite right; to the human eye we clearly should be fitting a circle, but this is a square with a rectangle sticking off of it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "For a random forest, we train a bunch of decision trees on different subsets of the data. Then we average their results. This gives us a much stronger classifier than any single decision tree can produce, and mitigates many of the negative effects of decision trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are some biological applications and examples of machine learning \n",
    "\n",
    "#### Useful resources for biologists getting into machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "* https://www.kaggle.com/raghuchaudhary/mushroom-classification\n",
    "* Aurélien Géron (2019) \"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition\". *O'Reilly Media, Inc.*  https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/\n",
    "* https://towardsdatascience.com/tidying-up-with-pca-an-introduction-to-principal-components-analysis-f876599af383\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
